\chapter{Analysis of existing methods}

  \section{Problem setup}

    \paragraph{}
    In this part we are going to set the mathematical framework for this study.
    We will start from a partial differential equation arising from the physical model, in the form of
    \begin{equation}\label{eq:pde}
      \frac{\partial \xi}{\partial t} + \operatorname{F}\left(\xi\right) = 0
    \end{equation}
    where the function $\operatorname{F}$ uses some space derivatives of the state variable $\xi$.
    This equation then describe the temporal evolution of the state variables $\xi$.

    \paragraph{}
    A particular class of such partial differential equations are conservative equations.
    They correspond to the case where the function $\operatorname{F}$ can be written as a divergence term.
    Finally, with a source term $\operatorname{S}$, those equations look like:
    \begin{equation}\label{eq:pde_conservative}
      \frac{\partial \xi}{\partial t} + \nabla \cdot \vec{\operatorname{f}}\left(\xi\right) = \operatorname{S}\ .
    \end{equation}
    One might notice that equation (\ref{eq:pde_conservative}) is indeed a particularisation of equation (\ref{eq:pde}), with $\operatorname{F}\left(\xi\right) = \nabla\cdot \vec{\operatorname{f}}\left(\xi\right) - \operatorname{S}$.
    Those conservative equations are the one we will focus on is this study, as they describe the physical systems we are interested in.

    \paragraph{}
    In this work, we will talk about computational fluid dynamics.
    We are in fact mostly interested in the Navier--Stokes equation, and its variants: the reactive Navier--Stokes equation, the Reynold-averaged Navier--Stokes equation, etc.
    A simple form of this equation can be:
    \begin{equation}\label{eq:ns}
      \left\{\begin{aligned}
        &\partial_t\left(\rho         \right) &&+ \nabla\cdot\left( \rho \vec{u} \right) &&= 0 \\
        &\partial_t\left(\rho \vec{u} \right) &&+ \nabla\cdot\left( \rho \vec{u} \otimes \vec{u} + p \id \right) &&= \nabla\cdot \mat{\tau}\\
        &\partial_t\left( \rho E      \right) &&+ \nabla\cdot\left( \left(\rho E + p\right) \vec{u} \right) &&=
          \nabla\cdot\left( \mat{\tau} \cdot \vec{u} \right)
      \end{aligned}\right.
    \end{equation}
    with the \PS{relation de fermeture} $\rho E = \frac{p}{\gamma - 1} + \rho\frac{\vec{u} \cdot \vec{u}}{2}$.
    The deviatoric stress tensor $\tau$ accounts for the viscosity of the fluid, and its computation depends on the model used.
    Without it, one recovers the Euler equations.
    To this simple form can be added source terms from the reactive model, source terms from the turbulence model, divergence terms from a diffusive model, etc.
    Yet it is clear that with a bit of rewriting, we can go back to the starting form (\ref{eq:pde}) and even the conservative form with source terms (\ref{eq:pde_conservative}).
    The quantity $\xi$ is no longer a scalar but a vector with the density $\rho$, each component of the momentum $\rho\vec{u}$ and the energy $\rho E$ as its components.
    Apart from this small change, the idea is the same.

    \paragraph{}
    When solving numerically equations like (\ref{eq:pde}), one must first take a spatial domain on interest.
    Let us call this domain $\mathcal{D}$.
    As we are interested in solving equations numerically, we need to be able to represent different quantities, such as the state variable $\xi$, numerically over the domain $\mathcal{D}$ and store it in the memory of a computer.
    Therefore we need to discretise the continuous spatial domain into a finite number of cells, or elements.
    This is usually done with a mesh of the domain $\mathcal{D}$.
    First we divide the domain $\mathcal{D}$ in a set of cells, called a mesh.
    Those cells are small volumes in 3D, faces in 2D or segments in 1D, disjoints, such as their union recovers the original domain.
    Interest quantities, such as the fluid velocity, density, \dots, are then stored at each nodes, averaged in the center of each cells or sometimes in a more complex fashion depending on the method.
    They are no longer mathematically represented by a function of the continuous physical domain $\xi : \mathcal{D} \rightarrow \mathbb{R}$ but by a finite sized vector $\Xi$ gathering all the information across the discretised domain.
    For some simple discretisation methods, this vector consists of the quantity evaluated at the mesh nodes or averaged at the center of the cells.
    For more complex methods, this vector consists of information used to construct the solution over the domain: polynomial coefficients, spectral decomposition coefficients, etc.
    Anyway, we no longer work in a continuous domain $\mathcal{D}$ but on a discretised one.

    \paragraph{}
    The partial differential equation (\ref{eq:pde}) transforms then into an ordinary differential equation:
    \begin{equation}\label{eq:ode}
      \frac{\partial \Xi}{\partial t} + \operatorname{G}\left(\Xi\right) = 0 \ .
    \end{equation}
    The difference here is that the function $\operatorname{G}$ is a function of a discrete vector whereas $\operatorname{F}$ was a function of a continuous function, and therefore $\operatorname{G}$ does not uses any spatial derivatives.
    Thanks to the spatial discretisation method, the only derivative remaining is with regard to time.
    The rest is then up to the temporal integration method, which is the main topic of this thesis.
    We will work from equation (\ref{eq:ode}) no matter where the function $\operatorname{G}$ comes from, but sometimes understanding the origin of this function can help so we will now introduce the spatial discretisation method used in our solver.


  \section{Brief introduction to the spatial integration schemes}

    \paragraph{}
    A \emph{spatial discretisation method} is the choice of how to represent a quantity over a discretised domain, and how to compute spatial derivative of this quantity from this representation.
    Indeed, before solving equation (\ref{eq:pde}) we need to decide how to transform the continuous model into a discretised one.
    We also have to look at how the spatial derivatives arising from equation (\ref{eq:pde}) translate in the discretised model.

    \subsection{The Finite Volumes method}

      \paragraph{}
      The spatial discretisation method used in the solver CHARME is called the Finite Volumes method \cite{EymardGallouetHerbin2000}.
      This method is particularly well fitted for conservatives equations such as equation (\ref{eq:pde_conservative}).
      Such equation has the property that the quantity $\xi$ is conserved: without source terms, the variation of the total quantity on $\xi$ over the domain $\mathcal{D}$ is equal to the flux $f\left(\xi\right)$ coming through the boundary $\partial\mathcal{D}$.
      In the case of the Navier--Stokes equations (\ref{eq:ns}), the density, the momentum and the energy are conserved throughout time, apart from what comes in and out of the domain.
      In a close domain where nothing comes in or out, they are indeed conserved.
      The main interest of the Finite Volumes method is that this property stays true through the spatial discretisation step.

      \paragraph{}
      The Finite Volumes method consists in integrating the partial differential equation over each cell of the mesh.
      Writing $\mathcal{V}_i$ the volume of the $i$th cell:
      \begin{equation}
        \int_{\mathcal{V}_i} \frac{\partial \xi}{\partial t} \mathrm{d}v + \int_{\mathcal{V}_i} \nabla\cdot \vec{\operatorname{f}}\left(\xi\right) \mathrm{d}v = \int_{\mathcal{V}_i} \operatorname{S} \mathrm{d}v\ .
      \end{equation}
      Then the Green--Ostrogradski theorem transforms the flux divergence into a \PS{bilan surfacique}:
      \begin{equation}
        \frac{\mathrm{d}}{\mathrm{d} t} \int_{\mathcal{V}_i} \xi\mathrm{d}v + \oint_{\partial\mathcal{V}_i} \vec{\operatorname{f}}\left(\xi\right) \cdot \vec{\mathrm{d}s} = \int_{\mathcal{V}_i} \operatorname{S} \mathrm{d}v\ .
      \end{equation}
      By writing $\square_i = \frac{1}{\left\|\mathcal{V}_i\right\|} \int_{\mathcal{V}_i} \square \mathrm{d}v$ the average in the $i$th cell, we then have:
      \begin{equation}
        \frac{\mathrm{d}\xi_i}{\mathrm{d} t}  + \frac{1}{\left\|\mathcal{V}_i\right\|} \oint_{\partial\mathcal{V}_i} \vec{\operatorname{f}}\left(\xi\right) \cdot \vec{\mathrm{d}s} = \operatorname{S}_i \ .
      \end{equation}

      \paragraph{}
      As stated before, the spatial discretisation method do transform the partial differential equation into an ordinary differential equation.
      It tells us to store our quantities as the averaged values represented at the center of gravity of each cells as our vector $\Xi$.
      It also tells us to compute the divergence from equation (\ref{eq:pde_conservative}) as a \PS{bilan surfacique de flux}.
      The last thing to do is to decide how to compute this \PS{bilan surfacique de flux}.
      The cells from our meshes are polygons.
      Therefore they have a finite number of (planar) faces.
      The integral over the boundary of the cell can be decomposed by the faces, to get the approximation:
      \begin{equation}
        \oint_{\partial\mathcal{V}_i} \vec{\operatorname{f}}\left(\xi\right) \cdot \vec{\mathrm{d}s} \approx \sum_{j\textrm{ neighbor of } i} \vec{\operatorname{f}}_{ij} \cdot \vec{s_{ij}}
      \end{equation}
      where $\vec{\operatorname{f}}_{ij} \cdot \vec{s_{ij}}$ is an approximation of the flux going through the face between cells $i$ and $j$.
      This approximation is a key element of the Finite Volumes method, therefore we will discuss it later.
      We can now compute the function $\operatorname{G}$ from equation (\ref{eq:ode}): for each face of the mesh we compute $\vec{\operatorname{f}}_{ij} \cdot \vec{s_{ij}}$, we add this value to the $i$th component and remove it from the $j$th component of our new vector.
      Then, after adding the source terms we get a vector containing the result of $\operatorname{G}\left(\Xi\right)$.
      As can be seen, every contribution of the flux added in a cell is removed from another, and therefore this spatial discretisation method preserves the conservativity of the underlying equation.


    \subsection{The Riemann problem}

      \PS{Déplacer après la reconstruction ? C'est plus fondamental mais ça intervient après}

      \paragraph{}
      The last remaining problem with this presentation of the Finite Volumes method is how to compute the flux going through cell interfaces.
      On the interfaces between two cells we know the left and right quantities $\xi_L$ and $\xi_R$, and we need to compute the corresponging flux.
      It is possible here to use a reconstruction method to get a better approximation of the quantities left and right of the interface, and therefore we end up using the left and right quantities $\xi_L^*$ and $\xi_R^*$.
      The idea is now to compute the flux going through the face as a function of $\xi_L^*$, $\xi_R^*$ and the surface vector $\vec{s}$.
      From the interface point of view, there are two possibly different states, one from each side: this is what is called a Rienamm problem.
      A Riemann problem is an initial value problem applied to a conservation equation, where the initial solution is piecewise constant with a single possible discontinuity.
      By working with the equation and deriving the jump condition, it is possible to compute the quantity at the interface from a possibly discontinuous state at the interface.
      Then it is possible to evaluate the flux associated with this state going through the surface.
      This approach can be called the exact Riemann solver as it uses the exact solution of the Riemann problem.
      But the drawback from this approach usually is the computational coast required to find this exact solution.
      What is usually done is to use approximate Riemann solvers, compromising between speed and accuracy.
      Several Riemann solvers\footnote{\PS{Est-ce qu'on parle toujours de solveur de Riemann (qui trouve la solution du problème idoine) ou on parle de "schéma de flux numérique" ?}} are available to the user in our solver, such as the well known Roe, HLLC or AUSM+ schemes \cite{Roe1981, Toro2009}.


    \subsection{Gradient reconstruction methods}

      \paragraph{}
      The standard Finite Volumes method represent quantities with the averaged value in each cell.
      This correspond to a first order discretisation method.
      Simply put, it means that it can represent quantities exactly as 0-th order polynomials locally to each cell.
      There are ways to achieve a higher order representation such as with the MUSCL approach \PS{(ref nécessaire ?)}.
      It consists in handling the surface flux evaluation on one hand, which is what we did in the Riemann problem part, and deciding what left and right quantities to feed to this flux computation on the other hand.
      In our solver, there are two ways to construct high order states to give to the flux computation method.
      They are described in the following parts.
      For both of them, the idea is to use neighboring data to enhance the order of the local representation.


      \subsubsection{The $k$-exact method}

        \paragraph{}
        The first method used to reconstruct high order quantities is called the \emph{$k$-exact} method.
        The idea is to construct iteratively an order $k$ representation of the quantity using the neighboring order $k-1$ representation \cite{HaiderCroisilleCourbet2009}.
        Usually, as do most of the solver users, this method is used to achieve a second order reconstruction.
        But it can also achieve higher order reconstructions \cite{HaiderCroisilleCourbet2011, HaiderCourbetCroisille2018, PontBrennerCinellaEtAl2017}.
        At each step, while increasing the order of the representation, it is important not to create a local maximum or minimum.
        This might happen close to discontinuities in the solution, or near rapidly varying spots \PS{reformuler}.
        It is indeed common, when interpolating, to create local overshoot or undershoot.
        One might think here about the Gibbs or Runge's phenomenons, and despite here being a different problem the idea is the same.
        Creating local extrema in the solution can be troublesome, and so the $k$-exact method limits the reconstructed polynomial to ensure it does not.


      \subsubsection{The Multislope method}

        \paragraph{}
        The second method used to reconstruct high order quantities is called the \emph{Multislope} method.
        At each face, this method computes a local gradient to interpolate the quantity from the center of the cell to the face.
        This gradient is obtained using neighboring data, with a complex mechanism that we will not discuss here \cite{LeTouzeMurroneGuillard2015}.
        Finally, the Multislope method gives a second order reconstruction.
        Once again, this reconstruction might create local maxima or minima, and therefore it uses slope limiters \cite{Venkatakrishnan1993, BergerAftosmis2005} to prevent it.


      \paragraph{}
      We briefly explained above the spatial discretisation method used in our solver, as it might help our analysis on the time integration part.
      The Finite Volumes method averages the partial differential equation over each cell of the mesh, which transforms the flux divergence into a \PS{bilan surfacique de flux}.
      A reconstruction method, the $k$-exact method or the Multislope method, is then used to get a higher order representation of the solution so that the surface flux can be computed at each face.
      Slope limiters are used to prevent the formation of local extrema, which can be harmful to the computation.


  \section{Time integration methods}

    \paragraph{}
    With the help of a spatial discretisation method, the equation we want to solve is now an ordinary differential equation.
    The main objective of this thesis is focused on the resolution of steady problems.
    The steady solution of equation (\ref{eq:ode}) is given by $\operatorname{G}\left(\Xi\right) = 0$.
    To get the solution, one might then try to find a root of the function $\operatorname{G}$.
    Unfortunately, with our typical applications, this function $\operatorname{G}$ has got bad mathematical properties, such as its stiffness, arising from the nonlinearities of the underlying equations.
    Therefore, algorithms that try to find a root of $\operatorname{G}$ struggle and usually fail.
    Another approach is to take an initial value $\Xi_0$, and to solve the equation (\ref{eq:ode}) for this initial value.
    After a long enough time, we hope that $\Xi$ will reach the desired steady solution.

    \paragraph{}
    The idea is now to solve the temporal evolution of $\Xi$ to get the solution after a long time, when it approaches the steady solution.
    We will solve the equation numerically, which mean we will iteratively compute the next solution after a given time step, knowing the current one.
    Is is also possible to modify the equation, as we are interested in the final state, not in the transient one.
    It is possible for example to use local time stepping, which consists in having each cell of the mesh moving forward in time with its own time step.
    The resulting transient states do not make sense from a physical point of vue, as the equation solved is not the initial one, but it converges to the same steady solution.
    Therefore, it is alright to change the equation as long as it gives the same steady solution.
    Finally, this way of finding a converged steady solution is what is called a \emph{Pseudo-Transient Continuation} method \cite{KelleyKeyes1996}.

    \paragraph{}
    We want to find the steady solution, and we are not interested in the evolution of the solution.
    It seems then reasonable to want to "go fast" to the steady state, meaning to use as large a time step as possible.
    Unfortunately, not every time integration method allows large time steps, as is well known \cite{CourantFriedrichsLewy1967}.
    We need to define some tool to help us decide on the method we will use.


    \subsection{Analyse des méthodes}

      \subsubsection{Consistance et ordre}


      \subsubsection{Stabilité}


    \subsection{Méthodes implicites}

      \subsubsection{Méthode d'Euler implicite}


      \subsubsection{Principe des méthodes implicites}
